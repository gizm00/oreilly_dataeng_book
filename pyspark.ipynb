{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypothesis_jsonschema import from_schema\n",
    "from importlib import reload # For reload to work need to import the module level for a method\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql import Row\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "import faker\n",
    "from pyspark.sql import functions as f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/07/16 13:42:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .appName('oreilly-book')\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "species_list = [\"night heron\", \"great blue heron\", \"grey heron\", \"whistling heron\"]\n",
    "species_regex = f\".*({'|'.join(species_list)}).*\"\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"inferSchema\", True).json('ch6_software/test_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = [{\"location\": [\"26.91756\", \"-82.07842\", \"Punta Gorda Isles\", \"US\", \"America/New_York\"]}]\n",
    "df_ex = spark.sparkContext.parallelize(ex).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------+---------------------+\n",
      "|location                                                      |lat_long             |\n",
      "+--------------------------------------------------------------+---------------------+\n",
      "|[26.91756, -82.07842, Punta Gorda Isles, US, America/New_York]|[26.91756, -82.07842]|\n",
      "+--------------------------------------------------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ex.withColumn(\"lat_long\", f.slice(f.col(\"location\"), 1, 2)).show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data = [{'description': \"Saw a night heron\"}]\n",
    "test_data_df = spark.sparkContext.parallelize(data).toDF()\n",
    "\n",
    "def apply_species_label(species_list, df):\n",
    "   return (df\n",
    "       .withColumn(\"description_lower\", f.lower('description'))\n",
    "       .withColumn(\"species\", f.regexp_extract('description_lower', species_regex, 1))\n",
    "       .drop(\"description_lower\")\n",
    "   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_list = ['night heron']\n",
    "result_df = apply_species_label(species_list, test_data_df)\n",
    "result = result_df.toPandas().to_dict('list')\n",
    "assert result['species'][0] == 'night heron'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "df = (spark\n",
    "         .read\n",
    "         .json('ch6_software/test_data.json')\n",
    "         .withColumn(\"description_lower\", f.lower('description'))\n",
    "         .withColumn(\"species\", f.regexp_extract('description_lower', species_regex, 1))\n",
    "         .drop(\"description_lower\")\n",
    "         .groupBy(\"species\")\n",
    "         .agg({\"count\":\"sum\"})\n",
    "         .write\n",
    "         .mode(\"overwrite\")\n",
    "         .json(\"ch6_software/result.json\")a\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "def get_json(file_name):\n",
    "    return spark.read.json(file_name)\n",
    "\n",
    "def apply_species_label(species_list, df):\n",
    "    return (df\n",
    "        .withColumn(\"description_lower\", f.lower('description'))\n",
    "        .withColumn(\"species\", f.regexp_extract('description_lower', species_regex, 1))\n",
    "        .drop(\"description_lower\")\n",
    "    )\n",
    "\n",
    "def create_aggregate_data(df):\n",
    "    return (df\n",
    "        .groupBy(\"species\")\n",
    "        .agg({\"count\":\"sum\"})\n",
    "        )\n",
    "\n",
    "def store_json(df, file_name):\n",
    "    (df.write\n",
    "        .mode(\"overwrite\")\n",
    "        .json(file_name))\n",
    "\n",
    "df = (get_json('ch6_software/test_data.json')\n",
    "        .transform(partial(apply_species_label, species_list))\n",
    "        .transform(create_aggregate_data)\n",
    ")\n",
    "\n",
    "store_json(df, 'ch6_software/result_chain.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex = [{\"location\": [\"26.91756\", \"-82.07842\", \"Punta Gorda Isles\", \"US\", \"America/New_York\"]}]\n",
    "df = (spark\n",
    "         .read\n",
    "         .json('ch6_software/test_data.json')\n",
    "         .withColumn(\"timezone\", f.slice(f.col(\"location\"), 5, 1))\n",
    "         .withColumn(\"description_lower\", f.lower('description'))\n",
    "         .withColumn(\"species\", f.regexp_extract('description_lower', species_regex, 1))\n",
    "         .drop(\"description_lower\")\n",
    "         .groupBy([\"timezone\",\"species\"])\n",
    "         .agg({\"count\":\"sum\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+----------+\n",
      "|            timezone|         species|sum(count)|\n",
      "+--------------------+----------------+----------+\n",
      "|   [America/Chicago]| whistling heron|         1|\n",
      "|   [America/Chicago]|                |        74|\n",
      "|[America/Los_Ange...|     night heron|        18|\n",
      "|[America/Los_Ange...|                |        71|\n",
      "|    [America/Denver]|     night heron|         1|\n",
      "|   [America/Detroit]|                |        19|\n",
      "|[America/Los_Ange...|great blue heron|        13|\n",
      "|[America/Indiana/...|great blue heron|        13|\n",
      "|  [America/New_York]|      grey heron|        19|\n",
      "|   [America/Detroit]|     night heron|        10|\n",
      "|  [America/New_York]|great blue heron|        15|\n",
      "|   [America/Chicago]|      grey heron|         4|\n",
      "|  [America/New_York]| whistling heron|         3|\n",
      "|  [America/New_York]|                |       133|\n",
      "|   [America/Chicago]|great blue heron|         6|\n",
      "+--------------------+----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_bucket gs://bestco/bird_data db postgres customer_id 1235\n",
      "source_bucket gs://for_the_birds db mysql customer_id 3423\n",
      "source_bucket s3://dtop324/z342_42ab db postgres customer_id 0953\n"
     ]
    }
   ],
   "source": [
    "def run_extract_species(source_bucket, db, customer_id):\n",
    "    print(\"source_bucket\", source_bucket, \"db\", db, \"customer_id\", customer_id)\n",
    "configs = [\n",
    "    {\"customer_id\": \"1235\", \"source_bucket\": \"gs://bestco/bird_data\", \"db\": \"postgres\"},\n",
    "    {\"customer_id\": \"3423\", \"source_bucket\": \"gs://for_the_birds\", \"db\": \"mysql\"},\n",
    "    {\"customer_id\": \"0953\", \"source_bucket\": \"s3://dtop324/z342_42ab\", \"db\": \"postgres\"},\n",
    "]\n",
    "for config in configs:\n",
    "    run_extract_species(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"fields\":[{\"metadata\":{},\"name\":\"count\",\"nullable\":true,\"type\":\"long\"},{\"metadata\":{},\"name\":\"description\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"img_files\",\"nullable\":true,\"type\":{\"containsNull\":true,\"elementType\":\"string\",\"type\":\"array\"}},{\"metadata\":{},\"name\":\"location\",\"nullable\":true,\"type\":{\"containsNull\":true,\"elementType\":\"string\",\"type\":\"array\"}},{\"metadata\":{},\"name\":\"user\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = df.schema\n",
    "schema_json = schema.json()\n",
    "schema.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, id, data):\n",
    "        self.id = id\n",
    "        self.data = data\n",
    "    def hello(self):\n",
    "        print(\"hello\", self.id)\n",
    "\n",
    "def thing(data, model_cls):\n",
    "    inst = model_cls(**data)\n",
    "    inst.hello()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello id\n"
     ]
    }
   ],
   "source": [
    "a =thing({'data':\"stuff\", 'id': \"id\"}, Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/07/28 20:14:26 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 900950 ms exceeds timeout 120000 ms\n",
      "22/07/28 20:14:26 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "def f(a, b):\n",
    "    print(a,b)\n",
    "\n",
    "c = {'a':1, 'b':2}\n",
    "f(**c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructField(count,LongType,true)\n",
      "StructField(description,StringType,true)\n",
      "StructField(img_files,ArrayType(StringType,true),true)\n",
      "StructField(location,ArrayType(StringType,true),true)\n",
      "StructField(user,StringType,true)\n"
     ]
    }
   ],
   "source": [
    "for field in schema.fields:\n",
    "    print(field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<map at 0x1127c9a00>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/53552983/how-to-generate-datasets-dynamically-based-on-schema\n",
    "map(lambda field: print(\"field\",field), schema.fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = faker.Faker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_values = {\n",
    "    (\"count\", T.LongType()): lambda: fake.random.randint(0, 20),\n",
    "    (\"description\", T.StringType()): lambda: fake.sentence(nb_words=10),\n",
    "    (\"user\",T.StringType()): lambda: fake.email(),\n",
    "}\n",
    "\n",
    "test_schema = T.StructType(\n",
    "    [T.StructField(\"count\",T.LongType(),True), \n",
    "    T.StructField(\"description\",T.StringType(),True),\n",
    "    T.StructField(\"user\",T.StringType(),True),\n",
    "    T.StructField(\"img_files\",T.ArrayType(T.StringType(),True),True),\n",
    "    T.StructField(\"location\",T.ArrayType(T.StringType(),True),True)]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([('count', LongType), ('description', StringType), ('user', StringType)])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_values.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value(name, dataType):\n",
    "    ret = dynamic_values.get((name, dataType))\n",
    "    # print(f\"Got {ret} for key ({name}, {dataType})\")\n",
    "    return ret()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8,\n",
       "  'Expect speech church spring travel race per off notice fine individual.',\n",
       "  'robinthomas@example.org'),\n",
       " (11, 'Glass TV say film paper system reduce.', 'christyfuentes@example.com'),\n",
       " (9,\n",
       "  'Through effect statement professor weight audience effect several know whether author.',\n",
       "  'lthompson@example.com'),\n",
       " (13,\n",
       "  'Practice when no may response contain structure tough everything grow.',\n",
       "  'chapmannichole@example.net'),\n",
       " (2,\n",
       "  'Congress popular new create industry control major travel.',\n",
       "  'richardsondavid@example.org'),\n",
       " (3,\n",
       "  'Fact although no feel environment every.',\n",
       "  'timothyanderson@example.com'),\n",
       " (16,\n",
       "  'Hour hot seven fast seven with address treat activity church hundred.',\n",
       "  'vkaufman@example.org'),\n",
       " (16,\n",
       "  'Traditional later page other gun space say from project.',\n",
       "  'dmitchell@example.net'),\n",
       " (17,\n",
       "  'Key indicate quite win kitchen service sort exactly general baby team again throughout.',\n",
       "  'tylerwhite@example.com'),\n",
       " (9,\n",
       "  'Senior control we nearly night leg economic drive attorney say night.',\n",
       "  'scottmiller@example.net')]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_samples = []\n",
    "for _ in range(10):\n",
    "    gen_samples.append(tuple(map(lambda field: get_value(field.name, field.dataType), test_schema.fields)))\n",
    "gen_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Row(<map object at 0x112e7c8b0>)>,\n",
       " <Row(<map object at 0x112e7ca00>)>,\n",
       " <Row(<map object at 0x112e7ceb0>)>,\n",
       " <Row(<map object at 0x112e77d30>)>,\n",
       " <Row(<map object at 0x112e773d0>)>,\n",
       " <Row(<map object at 0x112e777c0>)>,\n",
       " <Row(<map object at 0x112e770a0>)>,\n",
       " <Row(<map object at 0x112e777f0>)>,\n",
       " <Row(<map object at 0x112e77d60>)>,\n",
       " <Row(<map object at 0x112e77610>)>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------------------------------------------------------------------+---------------------------+\n",
      "|count|description                                                                            |user                       |\n",
      "+-----+---------------------------------------------------------------------------------------+---------------------------+\n",
      "|8    |Expect speech church spring travel race per off notice fine individual.                |robinthomas@example.org    |\n",
      "|11   |Glass TV say film paper system reduce.                                                 |christyfuentes@example.com |\n",
      "|9    |Through effect statement professor weight audience effect several know whether author. |lthompson@example.com      |\n",
      "|13   |Practice when no may response contain structure tough everything grow.                 |chapmannichole@example.net |\n",
      "|2    |Congress popular new create industry control major travel.                             |richardsondavid@example.org|\n",
      "|3    |Fact although no feel environment every.                                               |timothyanderson@example.com|\n",
      "|16   |Hour hot seven fast seven with address treat activity church hundred.                  |vkaufman@example.org       |\n",
      "|16   |Traditional later page other gun space say from project.                               |dmitchell@example.net      |\n",
      "|17   |Key indicate quite win kitchen service sort exactly general baby team again throughout.|tylerwhite@example.com     |\n",
      "|9    |Senior control we nearly night leg economic drive attorney say night.                  |scottmiller@example.net    |\n",
      "+-----+---------------------------------------------------------------------------------------+---------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/02 06:03:06 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 35448748 ms exceeds timeout 120000 ms\n",
      "22/06/02 06:03:07 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame(gen_samples, test_schema).show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'require'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake.word()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "integers()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from_schema(df.schema.jsonValue()['fields'][0])\n",
    "# df.schema.jsonValue()['fields'][0]\n",
    "from_schema({\"name\": \"count\", \"type\": \"integer\", \"nullable\": True, \"metadata\": {}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "integers(min_value=1, max_value=9)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_schema({\"type\": \"integer\", \"minimum\": 1, \"exclusiveMaximum\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "builds(error_raiser)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from_schema({'type': 'struct', 'fields': [{'name': 'count','type': 'integer','nullable': True,'metadata': {}}]})\n",
    "from_schema({'fields': [{'name': 'count','type': 'integer','nullable': True,'metadata': {}}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_schema = {\n",
    "    \"name\": \"user\", \"type\": \"text\",\n",
    "    \"name\": \"location\", \"type\": \"text\",\n",
    "    \"name\": \"description\", \"type\": \"text\",\n",
    "    \"name\": \"count\", \"type\": \"integer\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "integers()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/07 20:06:22 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 415090 ms exceeds timeout 120000 ms\n",
      "22/05/07 20:06:22 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "from_schema(test_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fb7b8bfb6ac614464896853891df516a4667eefc219e35743e3f3725c8af6be0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('oreilly-book')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
